{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import random\n",
    "from scipy import stats\n",
    "import glob\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declarations\n",
    "base_dir_data = \"data/\"\n",
    "base_dir_out = \"data/gtex_aggs/\"\n",
    "out_dir = \"analysis_21042020/\"\n",
    "hg38_fa = \"hg38_p12_ucsc.no_alts.no_fixs.fa\"\n",
    "\n",
    "num_tissues = 3\n",
    "num_samples = 10\n",
    "\n",
    "readlen = 101\n",
    "\n",
    "num_threads = 4\n",
    "\n",
    "gffread_path = \"gffread\"\n",
    "genRNAseq_path = \"soft/genRNAseq.R\"\n",
    "shuffleReads_path = \"soft/shuffleReads.sh\"\n",
    "\n",
    "gff3cols=[\"seqid\",\"source\",\"type\",\"start\",\"end\",\"score\",\"strand\",\"phase\",\"attributes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================\n",
      "Tissue #0\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first extract fasta sequences for each annotation\n",
    "for tissue_num in range(num_tissues):\n",
    "    print(\"\\n=================\\nTissue #\"+str(tissue_num)+\"\\n=================\\n\")\n",
    "    for sample_num in range(num_samples):\n",
    "        print(\"++++++\\n>Sample #\"+str(sample_num)+\"\\n++++++\\n\")\n",
    "        cmd_real = [gffread_path,\n",
    "                    \"-w\",out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\",\n",
    "                    \"-g\",hg38_fa,\n",
    "                    out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\"]\n",
    "        subprocess.call(cmd_real)\n",
    "\n",
    "        cmd_nonint = [gffread_path,\n",
    "                    \"-w\",out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\",\n",
    "                    \"-g\",hg38_fa,\n",
    "                    out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\"]\n",
    "        subprocess.call(cmd_nonint)\n",
    "\n",
    "        cmd_int = [gffread_path,\n",
    "                    \"-w\",out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\",\n",
    "                    \"-g\",hg38_fa,\n",
    "                    out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\"]\n",
    "        subprocess.call(cmd_int)\n",
    "\n",
    "        cmd_pol = [gffread_path,\n",
    "                    \"-w\",out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\",\n",
    "                    \"-g\",hg38_fa,\n",
    "                    out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\"]\n",
    "        subprocess.call(cmd_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================\n",
      "Tissue #0\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2\n",
      "=================\n",
      "\n",
      "++++++\n",
      ">Sample #0\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #1\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #2\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #3\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #4\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #5\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #6\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #7\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #8\n",
      "++++++\n",
      "\n",
      "++++++\n",
      ">Sample #9\n",
      "++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since gffread might have written data in the wrong order - we now need to reorganize the coverages\n",
    "# such that the order of extracted transcripts is the same as the order in the annotation and the order of coverages\n",
    "\n",
    "for tissue_num in range(num_tissues):\n",
    "    print(\"\\n=================\\nTissue #\"+str(tissue_num)+\"\\n=================\\n\")\n",
    "    for sample_num in range(num_samples):\n",
    "        print(\"++++++\\n>Sample #\"+str(sample_num)+\"\\n++++++\\n\")\n",
    "        tpm = pd.read_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".exp\",names=[\"tpm\"])\n",
    "        new_tpm = pd.read_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".tpm\",names=[\"new_tpm\"])\n",
    "        cov = pd.read_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".cov\",names=[\"cov\"])\n",
    "        gtf = pd.read_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\",names=gff3cols,sep=\"\\t\")\n",
    "        gtf[\"tid\"] = gtf[\"attributes\"].str.split(\"transcript_id \\\"\",expand=True,n=1)[1].str.split(\"\\\"\",expand=True,n=1)[0]\n",
    "        exps = gtf[gtf[\"type\"]==\"transcript\"].reset_index(drop=True)\n",
    "        exps[\"tpm_gtf\"] = exps[\"attributes\"].str.split(\"sim_tpm=\",expand=True,n=1)[1].str.split(\";\",expand=True,n=1)[0].astype(float)\n",
    "        # first check that tpms in the gtf correspond to tpms in the .exp file\n",
    "        exps = pd.concat([exps,tpm],axis=1)\n",
    "        assert len(exps[~(exps[\"tpm\"]==exps[\"tpm_gtf\"])])==0,\"incorrect tpms\"\n",
    "        # next we need to attach coverage and results\n",
    "        exps = pd.concat([exps,cov],axis=1)\n",
    "        # next we need to attach final tpms\n",
    "        exps = pd.concat([exps,new_tpm],axis=1)\n",
    "        exps = exps[[\"tid\",\"tpm_gtf\",\"cov\",\"new_tpm\"]]\n",
    "        # next we need to load the ordering of transcripts from the gffread\n",
    "        gffread_txs = []\n",
    "        with open(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\") as inFP:\n",
    "            for line in inFP.readlines():\n",
    "                if line[0]==\">\":\n",
    "                    gffread_txs.append(line[1:-1])\n",
    "        gffread_txs_df = pd.DataFrame(gffread_txs,columns=[\"tid\"])\n",
    "        # now order the all the files according to the order imposed by gffread\n",
    "        gtf = gffread_txs_df.merge(gtf,how=\"left\",on=\"tid\")\n",
    "        # lastly need to save new data\n",
    "        gtf[gff3cols].to_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".sorted.gtf\",sep=\"\\t\",index=False,header=False,quoting=csv.QUOTE_NONE)\n",
    "        # save the tpms and coverages now\n",
    "        exps = gffread_txs_df.merge(exps,how=\"left\",on=\"tid\")\n",
    "        exps[[\"tpm_gtf\"]].to_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.exp\",index=False,header=False)\n",
    "        exps[[\"cov\"]].to_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.cov\",index=False,header=False)\n",
    "        exps[[\"new_tpm\"]].to_csv(out_dir+\"real.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.tpm\",index=False,header=False)\n",
    "\n",
    "        tpm = pd.read_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".exp\",names=[\"tpm\"])\n",
    "        new_tpm = pd.read_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".tpm\",names=[\"new_tpm\"])\n",
    "        cov = pd.read_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".cov\",names=[\"cov\"])\n",
    "        gtf = pd.read_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\",names=gff3cols,sep=\"\\t\")\n",
    "        gtf[\"tid\"] = gtf[\"attributes\"].str.split(\"transcript_id \\\"\",expand=True,n=1)[1].str.split(\"\\\"\",expand=True,n=1)[0]\n",
    "        exps = gtf[gtf[\"type\"]==\"transcript\"].reset_index(drop=True)\n",
    "        exps[\"tpm_gtf\"] = exps[\"attributes\"].str.split(\"sim_tpm=\",expand=True,n=1)[1].str.split(\";\",expand=True,n=1)[0].astype(float)\n",
    "        # first check that tpms in the gtf correspond to tpms in the .exp file\n",
    "        exps = pd.concat([exps,tpm],axis=1)\n",
    "        assert len(exps[~(exps[\"tpm\"]==exps[\"tpm_gtf\"])])==0,\"incorrect tpms\"\n",
    "        #next we need to attach coverage and results\n",
    "        exps = pd.concat([exps,cov],axis=1)\n",
    "        # next we need to attach final tpms\n",
    "        exps = pd.concat([exps,new_tpm],axis=1)\n",
    "        exps = exps[[\"tid\",\"tpm_gtf\",\"cov\",\"new_tpm\"]]\n",
    "        # next we need to load the ordering of transcripts from the gffread\n",
    "        gffread_txs = []\n",
    "        with open(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\") as inFP:\n",
    "            for line in inFP.readlines():\n",
    "                if line[0]==\">\":\n",
    "                    gffread_txs.append(line[1:-1])\n",
    "        gffread_txs_df = pd.DataFrame(gffread_txs,columns=[\"tid\"])\n",
    "        # now order the all the files according to the order imposed by gffread\n",
    "        gtf = gffread_txs_df.merge(gtf,how=\"left\",on=\"tid\")\n",
    "        # lastly need to save new data\n",
    "        gtf[gff3cols].to_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".sorted.gtf\",sep=\"\\t\",index=False,header=False,quoting=csv.QUOTE_NONE)\n",
    "        # save the tpms and coverages now\n",
    "        exps = gffread_txs_df.merge(exps,how=\"left\",on=\"tid\")\n",
    "        exps[[\"tpm_gtf\"]].to_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.exp\",index=False,header=False)\n",
    "        exps[[\"cov\"]].to_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.cov\",index=False,header=False)\n",
    "        exps[[\"new_tpm\"]].to_csv(out_dir+\"splicing.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.tpm\",index=False,header=False)\n",
    "\n",
    "        tpm = pd.read_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".exp\",names=[\"tpm\"])\n",
    "        new_tpm = pd.read_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".tpm\",names=[\"new_tpm\"])\n",
    "        cov = pd.read_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".cov\",names=[\"cov\"])\n",
    "        gtf = pd.read_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\",names=gff3cols,sep=\"\\t\")\n",
    "        gtf[\"tid\"] = gtf[\"attributes\"].str.split(\"transcript_id \\\"\",expand=True,n=1)[1].str.split(\"\\\"\",expand=True,n=1)[0]\n",
    "        exps = gtf[gtf[\"type\"]==\"transcript\"].reset_index(drop=True)\n",
    "        exps[\"tpm_gtf\"] = exps[\"attributes\"].str.split(\"sim_tpm=\",expand=True,n=1)[1].str.split(\";\",expand=True,n=1)[0].astype(float)\n",
    "        # first check that tpms in the gtf correspond to tpms in the .exp file\n",
    "        exps = pd.concat([exps,tpm],axis=1)\n",
    "        assert len(exps[~(exps[\"tpm\"]==exps[\"tpm_gtf\"])])==0,\"incorrect tpms\"\n",
    "        #next we need to attach coverage and results\n",
    "        exps = pd.concat([exps,cov],axis=1)\n",
    "        # next we need to attach final tpms\n",
    "        exps = pd.concat([exps,new_tpm],axis=1)\n",
    "        exps = exps[[\"tid\",\"tpm_gtf\",\"cov\",\"new_tpm\"]]\n",
    "        # next we need to load the ordering of transcripts from the gffread\n",
    "        gffread_txs = []\n",
    "        with open(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\") as inFP:\n",
    "            for line in inFP.readlines():\n",
    "                if line[0]==\">\":\n",
    "                    gffread_txs.append(line[1:-1])\n",
    "        gffread_txs_df = pd.DataFrame(gffread_txs,columns=[\"tid\"])\n",
    "        # now order the all the files according to the order imposed by gffread\n",
    "        gtf = gffread_txs_df.merge(gtf,how=\"left\",on=\"tid\")\n",
    "        # lastly need to save new data\n",
    "        gtf[gff3cols].to_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".sorted.gtf\",sep=\"\\t\",index=False,header=False,quoting=csv.QUOTE_NONE)\n",
    "        # save the tpms and coverages now\n",
    "        exps = gffread_txs_df.merge(exps,how=\"left\",on=\"tid\")\n",
    "        exps[[\"tpm_gtf\"]].to_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.exp\",index=False,header=False)\n",
    "        exps[[\"cov\"]].to_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.cov\",index=False,header=False)\n",
    "        exps[[\"new_tpm\"]].to_csv(out_dir+\"intronic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.tpm\",index=False,header=False)\n",
    "\n",
    "        tpm = pd.read_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".exp\",names=[\"tpm\"])\n",
    "        new_tpm = pd.read_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".tpm\",names=[\"new_tpm\"])\n",
    "        cov = pd.read_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".cov\",names=[\"cov\"])\n",
    "        gtf = pd.read_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".gtf\",names=gff3cols,sep=\"\\t\")\n",
    "        gtf[\"tid\"] = gtf[\"attributes\"].str.split(\"transcript_id \\\"\",expand=True,n=1)[1].str.split(\"\\\"\",expand=True,n=1)[0]\n",
    "        exps = gtf[gtf[\"type\"]==\"transcript\"].reset_index(drop=True)\n",
    "        exps[\"tpm_gtf\"] = exps[\"attributes\"].str.split(\"sim_tpm=\",expand=True,n=1)[1].str.split(\";\",expand=True,n=1)[0].astype(float)\n",
    "        # first check that tpms in the gtf correspond to tpms in the .exp file\n",
    "        exps = pd.concat([exps,tpm],axis=1)\n",
    "        assert len(exps[~(exps[\"tpm\"]==exps[\"tpm_gtf\"])])==0,\"incorrect tpms\"\n",
    "        #next we need to attach coverage and results\n",
    "        exps = pd.concat([exps,cov],axis=1)\n",
    "        # next we need to attach final tpms\n",
    "        exps = pd.concat([exps,new_tpm],axis=1)\n",
    "        exps = exps[[\"tid\",\"tpm_gtf\",\"cov\",\"new_tpm\"]]\n",
    "        # next we need to load the ordering of transcripts from the gffread\n",
    "        gffread_txs = []\n",
    "        with open(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".fasta\") as inFP:\n",
    "            for line in inFP.readlines():\n",
    "                if line[0]==\">\":\n",
    "                    gffread_txs.append(line[1:-1])\n",
    "        gffread_txs_df = pd.DataFrame(gffread_txs,columns=[\"tid\"])\n",
    "        # now order the all the files according to the order imposed by gffread\n",
    "        gtf = gffread_txs_df.merge(gtf,how=\"left\",on=\"tid\")\n",
    "        # lastly need to save new data\n",
    "        gtf[gff3cols].to_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".sorted.gtf\",sep=\"\\t\",index=False,header=False,quoting=csv.QUOTE_NONE)\n",
    "        # save the tpms and coverages now\n",
    "        exps = gffread_txs_df.merge(exps,how=\"left\",on=\"tid\")\n",
    "        exps[[\"tpm_gtf\"]].to_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.exp\",index=False,header=False)\n",
    "        exps[[\"cov\"]].to_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.cov\",index=False,header=False)\n",
    "        exps[[\"new_tpm\"]].to_csv(out_dir+\"intergenic.t\"+str(tissue_num)+\"_s\"+str(sample_num)+\".ordered.tpm\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sample\n",
    "def gen_sample(ts):\n",
    "    tn = ts[0]\n",
    "    sn = ts[1]\n",
    "    print(\"\\n=================\\nTissue #\"+str(tn)+\" - Sample #\"+str(sn)+\"\\n=================\\n\")\n",
    "    if not os.path.exists(out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cmd_real = [genRNAseq_path,\n",
    "                out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".fasta\",\n",
    "                out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".ordered.cov\",\n",
    "                str(readlen),\n",
    "                out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/\",\n",
    "                \"0\"]\n",
    "    subprocess.call(cmd_real)\n",
    "\n",
    "    if not os.path.exists(out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cmd_nonint = [genRNAseq_path,\n",
    "                out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\".fasta\",\n",
    "                out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\".ordered.cov\",\n",
    "                str(readlen),\n",
    "                out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/\",\n",
    "                \"0\"]\n",
    "    subprocess.call(cmd_nonint)\n",
    "\n",
    "    if not os.path.exists(out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cmd_int = [genRNAseq_path,\n",
    "                out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\".fasta\",\n",
    "                out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\".ordered.cov\",\n",
    "                str(readlen),\n",
    "                out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/\",\n",
    "                \"0\"]\n",
    "    subprocess.call(cmd_int)\n",
    "\n",
    "    if not os.path.exists(out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cmd_pol = [genRNAseq_path,\n",
    "                out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\".fasta\",\n",
    "                out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\".ordered.cov\",\n",
    "                str(readlen),\n",
    "                out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/\",\n",
    "                \"0\"]\n",
    "    subprocess.call(cmd_pol)\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for tn in range(num_tissues):\n",
    "    for sn in range(num_samples):\n",
    "        samples.append((tn,sn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=num_threads)\n",
    "pool_outputs = pool.map(gen_sample, samples)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Pool:', pool_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_combine(ts):\n",
    "    tn = ts[0]\n",
    "    sn = ts[1]\n",
    "    print(\"\\n=================\\nTissue #\"+str(tn)+\" - Sample #\"+str(sn)+\"\\n=================\\n\")       \n",
    "    shuffle_cmd = [shuffleReads_path,\n",
    "                   out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\",\n",
    "                   out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.shuffled.fasta\"]\n",
    "    subprocess.call(shuffle_cmd)\n",
    "\n",
    "    # create a combination of real and nonint\n",
    "    if not os.path.exists(out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cat_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta > \"+\\\n",
    "                      out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\"]\n",
    "    subprocess.call(cat_cmd,shell=True)\n",
    "    shuffle_cmd = [shuffleReads_path,\n",
    "                   out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\",\n",
    "                   out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.shuffled.fasta\"]\n",
    "    subprocess.call(shuffle_cmd)\n",
    "\n",
    "    # create a combination of real and int\n",
    "    if not os.path.exists(out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cat_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta > \"+\\\n",
    "                      out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\"]\n",
    "    subprocess.call(cat_cmd,shell=True)\n",
    "    shuffle_cmd = [shuffleReads_path,\n",
    "                   out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\",\n",
    "                   out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.shuffled.fasta\"]\n",
    "    subprocess.call(shuffle_cmd)\n",
    "\n",
    "    # create a combination of real and polymerase\n",
    "    if not os.path.exists(out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cat_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta > \"+\\\n",
    "                      out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\"]\n",
    "    subprocess.call(cat_cmd,shell=True)\n",
    "    shuffle_cmd = [shuffleReads_path,\n",
    "                   out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\",\n",
    "                   out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.shuffled.fasta\"]\n",
    "    subprocess.call(shuffle_cmd)\n",
    "\n",
    "    # create a combination of all reads\n",
    "    if not os.path.exists(out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)):\n",
    "        os.makedirs(out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn))\n",
    "    cat_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta \"+\\\n",
    "                      out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta > \"+\\\n",
    "                      out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\"]\n",
    "    subprocess.call(cat_cmd,shell=True)\n",
    "    shuffle_cmd = [shuffleReads_path,\n",
    "                   out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\",\n",
    "                   out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.shuffled.fasta\"]\n",
    "    subprocess.call(shuffle_cmd)\n",
    "\n",
    "    os.remove(out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "#     os.remove(out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "#     os.remove(out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "#     os.remove(out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "    os.remove(out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "    os.remove(out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "    os.remove(out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")\n",
    "    os.remove(out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)+\"/sample_01.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================\n",
      "Tissue #0 - Sample #2\n",
      "=================\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #0\n",
      "=================\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #7\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #0\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #2\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #9\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #0\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #2\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #7\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #9\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #9\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #7\n",
      "=================\n",
      "\n",
      "Pool: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes=num_threads)\n",
    "pool_outputs = pool.map(shuffle_combine, samples)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Pool:', pool_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gffs(ts):\n",
    "    tn = ts[0]\n",
    "    sn = ts[1]\n",
    "    print(\"\\n=================\\nTissue #\"+str(tn)+\" - Sample #\"+str(sn)+\"\\n=================\\n\")\n",
    "    merge_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       \" > \"+out_dir+\"real_splicing.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf\"]\n",
    "    subprocess.call(merge_cmd,shell=True)\n",
    "\n",
    "    merge_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       \" > \"+out_dir+\"real_intronic.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf\"]\n",
    "    subprocess.call(merge_cmd,shell=True)\n",
    "\n",
    "    merge_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       out_dir+\"intergenic.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       \" > \"+out_dir+\"real_intergenic.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf\"]\n",
    "    subprocess.call(merge_cmd,shell=True)\n",
    "\n",
    "    merge_cmd = [\"cat \"+out_dir+\"real.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       out_dir+\"splicing.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       out_dir+\"intronic.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf \"+\\\n",
    "                       \" > \"+out_dir+\"all.t\"+str(tn)+\"_s\"+str(sn)+\".sorted.gtf\"]\n",
    "    subprocess.call(merge_cmd,shell=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================\n",
      "Tissue #0 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #0\n",
      "=================\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #2\n",
      "=================\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #7\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #0\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #2\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #0 - Sample #9\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #0\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #2\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #7\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #1 - Sample #9\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #1\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #3\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #4\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #6\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #8\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #5\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #7\n",
      "=================\n",
      "\n",
      "\n",
      "=================\n",
      "Tissue #2 - Sample #9\n",
      "=================\n",
      "\n",
      "Pool: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes=num_threads)\n",
    "pool_outputs = pool.map(combine_gffs, samples)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Pool:', pool_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
